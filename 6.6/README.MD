**1.** Выполняемые операции в MongoDB можно проверить с помощью db.currentOp(). Определив нужную, ее можно принудительно завершить db.killOp(). Чтобы избежать проблемы долгих CRUD операций в дальнейшем можно отрегулировать время на их исполнение с помощью maxTimeMS()

**2.** Очень похоже, что дело в ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP удаляющим ключи с истекшим сроком действия. Если в БД есть много-много ключей, срок действия которых истекает в ту же секунду, и они составляют не менее 25% от текущего множества ключей, Redis может заблокировать их, чтобы сделать процент ключей, срок действия которых уже истек, ниже 25%.

**3.** Ошибка говорит нам о невозможности соединится с БД во время выполнения запроса. Официальная документация говорит нам о следующих вероятных проблемах:
- сетевые неполадки, следует диагностировать и исключить их, перед дальнейшими действиями
- возможен вариант когда в рамках запроса его объем очень велик (миллионы строк), в этом случае рекомендовано увеличить параметр net_read_timeout
- если в логах встречается ER_NET_PACKET_TOO_LARGE это говорит о превышении буфера
max_allowed_packet и его следует увеличить на стороне сервера и клиента
- с более редкой вероятностью может быть ситуация, когда клиент не успевает установить соединение. Решением может служить корректировка значения  connect_timeout в большую сторону

**4.** В данном случае говорится о вызове OOM Killer - служебном процессе, завершающим приложения, вызываемый ядром, когда системе критически не хватает памяти. 
Возможные действия для  решения проблемы:
- выделить больше ресурсов серверу
- перенести или отключить другие приложения потребляющие память сервера
- при помощи vm.overcommit_memory и vm.overcommit_ratio отрегулировать перевыделение памяти для процессов
- перенастроить OOM Killer так, чтобы процесс postman(postgres) имел более низкие шансы на отключение 

